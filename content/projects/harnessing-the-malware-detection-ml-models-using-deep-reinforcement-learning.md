+++
author = "ipark"
title = "Harnessing the Malware Detection ML Models Using Deep Reinforcement Learning"
draft =  false
type = "projects"
layout = "projects"
description = ""
tags = ["project", "Malware Evasion", "Malware Detection", "Deep Reinforcement Learning"
]
+++

#### Abstract:
<blockquote>
<p>Final aim of this project is to harness malware detection machine learning (ML) models using deep reinforcement learning (DRL). There are two stages toward the final goal:</p>
<ul>
<li>Malware writer&rsquo;s perspective to weaken malware detector :
generating invasive malware data representing the adversarial space to evade the ML detection model</li>
<li>Malware defender&rsquo;s perspective to harness malware detector :  using the generated adversarial data, retraining the malware detection ML model in several rounds in a iterative manner for more robust malware detection capability.</li>
</ul>
<p>Currently this project is at the first phase. The DRL framework let the agent to learn the value-function in end-to-end way (input → black-box → output):</p>
<p>Input of the DRL Environment is malware portable executable (PE) files.
Outputs from the DRL Environment are
the estimated reward (more reward to the successful evasion); and
action-state policy (sequence of state-action mapping, where state is PE feature vectors; action is mutation on the PE files).</p>
<p>The objective function for the DRL Agent to learn is a value-function (i.e.
accumulative, discounted reward values) that allows efficiently selecting an action that mutates the PE file to be misclassified as benign (but preserving malign functionality in disguise).</p>
</blockquote>
