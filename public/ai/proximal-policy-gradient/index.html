<!DOCTYPE html>
<html>
<head><meta charset="utf-8"><meta name="generator" content="Hugo 0.83.1" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark">

<meta name="keywords" content=>
<meta name="description" content="">
<meta name="author" content=ipark>
<meta name="copyright"content=ipark>
<meta http-equiv="content-language" content="zh,en">



<link rel="canonical" href="https://ipark-cs.github.io/ai/proximal-policy-gradient/">


<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff"><title>Proximal Policy Gradient&nbsp;&ndash;&nbsp;iPark memoization</title><link rel="preconnect" href="https://cdn.jsdelivr.net/" crossorigin>
<link rel="dns-prefetch" href="https://cdn.jsdelivr.net/">
<link rel="dns-prefetch" href="https://fonts.gstatic.com/"><link rel="preload" href="/css/core.min.fdf2dd6d920f0ce72f788d5ff5a1f4feb164ffab9b790386b133d340e7b51bbe8fba56050bf2e4919342447cbccdffbd.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="/css/core.min.fdf2dd6d920f0ce72f788d5ff5a1f4feb164ffab9b790386b133d340e7b51bbe8fba56050bf2e4919342447cbccdffbd.css" integrity="sha384-/fLdbZIPDOcveI1f9aH0/rFk/6ubeQOGsTPTQOe1G76PulYFC/LkkZNCRHy8zf&#43;9"></noscript>
<style type="text/css">*,::before,::after{margin:0;padding:0;box-sizing:border-box}html{font-family:-system-ui,-apple-system,BlinkMacSystemFont,helvetica neue,Helvetica,Arial,sans-serif,apple color emoji,segoe ui emoji,segoe ui symbol;font-size:17px;font-weight:400;line-height:1.7;scroll-behavior:smooth;transition:color .3s,background-color .3s;word-wrap:break-word;-webkit-text-size-adjust:100%}html[data-theme=dark] img{opacity:.65;transition:opacity .5s ease-in-out}html{background:#fff;--site-name-color:#3f4b67;--color-primary:#005ab4;--link-underline:#90cff9;--blockquote-border-left:6px solid #0051a2;--block-background-color:#f7faff;--pag-background-color:rgba(0, 122, 255, .5);--box-shadow:1px 1px 2px rgba(0,0,0,.125);--title-color:#303033;--body-color:#444}html[data-theme=dark]{background:#22272e;--site-name-color:#539bf5;--color-primary:#99bde1;--link-underline:#0051a2;--blockquote-border-left:6px solid #5176bf;--block-background-color:#002c58;--box-shadow:none;--title-color:#dadada;--body-color:#e9e9e9}h1,h2,h3,h4,h5,h6{font-weight:600;line-height:1.3;margin-block-start:0;margin-block-end:0}h1{font-size:26px}h2{font-size:24px}h3{font-size:22px}section>h1{color:var(--title-color)}a{color:var(--color-primary);text-decoration-thickness:.15rem;text-decoration-color:var(--link-underline)}a:hover{text-decoration-color:var(--color-primary)}.wrapper{display:grid;grid-template-columns:1fr min(65ch,calc(100% - 64px))1fr;grid-column-gap:32px}.wrapper>section{grid-column:2}.header{margin:20px 0;display:-webkit-flex;display:flex;flex-wrap:wrap;text-align:initial;padding:15px 0;border-bottom:1px solid #f0f0f0;justify-content:space-between;align-items:baseline}.site-name{display:inline-block;font-weight:600;font-size:21px;color:var(--site-name-color)}.site-logo{height:38px;border-radius:3px;vertical-align:middle;margin-right:8px}.nav-item{display:inline-block;font-size:18px;padding:4px 6px;margin:2px 3px 2px 0;line-height:1.5;white-space:nowrap}.data-theme-btn{border:none;vertical-align:middle;transition:.3s;background-color:Transparent;background-repeat:no-repeat;cursor:pointer;overflow:hidden;outline:none;padding-right:0;padding-left:0}html[data-theme=light] .light-hidden{display:none}html[data-theme=dark] .dark-hidden{display:none}.note-list{margin:0;padding:0;list-style:none}.note-list .item{position:relative;width:100%;margin-top:25px}.note-list .item:last-child{border:0!important}.note-title{font-size:19px;font-weight:700}.note-date,.note-content{font-size:15px;text-decoration:none;color:var(--body-color)}.note-content,.note-imgs,.note-labels{margin-top:4px;text-align:justify;text-justify:inter-word}.article-tag,.article-category{display:inline-block;font-size:15px;line-height:1;padding:4px 6px;margin:2px 3px 2px 0;white-space:nowrap;border-radius:3px}.article-category{color:#3a8c42}.article-category .hashtag,.article-tag .hashtag{font-weight:700;opacity:.5}.footer{font-size:13px;margin:40px 0 20px}.footer-wrap{text-align:center;color:var(--body-color)}.tag-cloud{margin:2em 0 3em;text-align:center}.tag-cloud-tags{display:inline-block;position:relative;margin:5px;word-wrap:break-word;overflow-wrap:break-word}.archive-year{font-size:20px;font-weight:800;color:var(--title-color);margin-top:20px;margin-bottom:10px}.archive-list{list-style:none}.archive-date{flex:0 0 100px;color:var(--title-color)}.archive-text{color:var(--body-color)}ul.archive-list li{display:flex}.article-containter{margin-bottom:20px}.article-header{margin:20px 0}.article-date{font-size:14px;margin-top:20px;color:#838387}.markdown-body{color:var(--body-color)}.markdown-body p{margin-top:0;margin-bottom:20px}.pagination{display:block;text-align:center;margin:20px 0 40px}.pagination ul{display:inline-block;list-style:none;font-weight:600;padding:0;margin:0}.pagination ul li{display:inline}.pagination ul li a{color:var(--color-primary);float:left;padding:8px 16px;text-decoration:none}.pagination ul li a:hover:not(.active){background-color:var(--pag-background-color)}.pagination ul li a.active{background-color:var(--color-primary);color:var(--block-background-color)}@font-face{font-family:averia sans libre;font-style:italic;font-weight:300;font-display:swap;src:local('Averia Sans Libre Light Italic'),local('AveriaSansLibre-LightItalic'),url(https://fonts.gstatic.com/s/averiasanslibre/v8/ga6caxZG_G5OvCf_rt7FH3B6BHLMEdVLKisSH5DdLw.ttf)format('truetype')}@font-face{font-family:averia sans libre;font-style:italic;font-weight:400;font-display:swap;src:local('Averia Sans Libre Italic'),local('AveriaSansLibre-Italic'),url(https://fonts.gstatic.com/s/averiasanslibre/v8/ga6RaxZG_G5OvCf_rt7FH3B6BHLMEdVLIoAwDw.ttf)format('truetype')}@font-face{font-family:averia sans libre;font-style:italic;font-weight:700;font-display:swap;src:local('Averia Sans Libre Bold Italic'),local('AveriaSansLibre-BoldItalic'),url(https://fonts.gstatic.com/s/averiasanslibre/v8/ga6caxZG_G5OvCf_rt7FH3B6BHLMEdVLKjsVH5DdLw.ttf)format('truetype')}@font-face{font-family:averia sans libre;font-style:normal;font-weight:300;font-display:swap;src:local('Averia Sans Libre Light'),local('AveriaSansLibre-Light'),url(https://fonts.gstatic.com/s/averiasanslibre/v8/ga6SaxZG_G5OvCf_rt7FH3B6BHLMEd3lMJcXL5c.ttf)format('truetype')}@font-face{font-family:averia sans libre;font-style:normal;font-weight:400;font-display:swap;src:local('Averia Sans Libre Regular'),local('AveriaSansLibre-Regular'),url(https://fonts.gstatic.com/s/averiasanslibre/v8/ga6XaxZG_G5OvCf_rt7FH3B6BHLMEdVOEoc.ttf)format('truetype')}@font-face{font-family:averia sans libre;font-style:normal;font-weight:700;font-display:swap;src:local('Averia Sans Libre Bold'),local('AveriaSansLibre-Bold'),url(https://fonts.gstatic.com/s/averiasanslibre/v8/ga6SaxZG_G5OvCf_rt7FH3B6BHLMEd31N5cXL5c.ttf)format('truetype')}@font-face{font-family:source code pro;font-style:italic;font-weight:400;font-display:swap;src:local('Source Code Pro Italic'),local('SourceCodePro-It'),url(https://fonts.gstatic.com/s/sourcecodepro/v11/HI_QiYsKILxRpg3hIP6sJ7fM7PqlONvUlMc.ttf)format('truetype')}@font-face{font-family:source code pro;font-style:italic;font-weight:500;font-display:swap;src:local('Source Code Pro Medium Italic'),local('SourceCodePro-MediumIt'),url(https://fonts.gstatic.com/s/sourcecodepro/v11/HI_ViYsKILxRpg3hIP6sJ7fM7PqlONMnt9co5mg.ttf)format('truetype')}@font-face{font-family:source code pro;font-style:italic;font-weight:600;font-display:swap;src:local('Source Code Pro SemiBold Italic'),local('SourceCodePro-SemiBoldIt'),url(https://fonts.gstatic.com/s/sourcecodepro/v11/HI_ViYsKILxRpg3hIP6sJ7fM7PqlONMLsNco5mg.ttf)format('truetype')}@font-face{font-family:source code pro;font-style:italic;font-weight:700;font-display:swap;src:local('Source Code Pro Bold Italic'),local('SourceCodePro-BoldIt'),url(https://fonts.gstatic.com/s/sourcecodepro/v11/HI_ViYsKILxRpg3hIP6sJ7fM7PqlONNvsdco5mg.ttf)format('truetype')}@font-face{font-family:source code pro;font-style:normal;font-weight:400;font-display:swap;src:local('Source Code Pro Regular'),local('SourceCodePro-Regular'),url(https://fonts.gstatic.com/s/sourcecodepro/v11/HI_SiYsKILxRpg3hIP6sJ7fM7PqlPevT.ttf)format('truetype')}@font-face{font-family:source code pro;font-style:normal;font-weight:500;font-display:swap;src:local('Source Code Pro Medium'),local('SourceCodePro-Medium'),url(https://fonts.gstatic.com/s/sourcecodepro/v11/HI_XiYsKILxRpg3hIP6sJ7fM7PqtzsjDs-cv.ttf)format('truetype')}@font-face{font-family:source code pro;font-style:normal;font-weight:600;font-display:swap;src:local('Source Code Pro SemiBold'),local('SourceCodePro-SemiBold'),url(https://fonts.gstatic.com/s/sourcecodepro/v11/HI_XiYsKILxRpg3hIP6sJ7fM7Pqt4s_Ds-cv.ttf)format('truetype')}@font-face{font-family:source code pro;font-style:normal;font-weight:700;font-display:swap;src:local('Source Code Pro Bold'),local('SourceCodePro-Bold'),url(https://fonts.gstatic.com/s/sourcecodepro/v11/HI_XiYsKILxRpg3hIP6sJ7fM7Pqths7Ds-cv.ttf)format('truetype')}html{font-family:averia sans libre,-system-ui,-apple-system,BlinkMacSystemFont,helvetica neue,Helvetica,SimHei,segoe ui,Roboto,Arial,sans-serif,apple color emoji,segoe ui emoji,segoe ui symbol}code,pre,tt,kbd,samp{font-family:source code pro,Menlo,Consolas,liberation mono,monospace;font-weight:500}</style>
</head>

<body>
    <div class="wrapper"><section id="header" class="header">
        <div class="header-left"><a href="/"><p class="site-name">iPark memoization</p></a>
        </div>
        <div class="header-right"><div class="nav"><a class="nav-item" href="/tags/">Tags</a><a class="nav-item" href="/projects/">cs.Projects</a><a class="nav-item" href="/research/">bio.Research</a><a class="nav-item" href="/about/">resume</a><script>
  const htmlEl = document.getElementsByTagName('html')[0];
  const currentTheme = localStorage.getItem('theme') ? localStorage.getItem('theme') : null;
  if (currentTheme) {
    htmlEl.dataset.theme = currentTheme;
  }
  const toggleTheme = (theme) => {
    htmlEl.dataset.theme = theme;
    localStorage.setItem('theme', theme);
  }
  if (
    localStorage.getItem('theme') === 'dark' ||
    window.matchMedia &&
    window.matchMedia("(prefers-color-scheme: dark)").matches
  ) {
    htmlEl.dataset.theme = 'dark';
  } else {
    toggleTheme('light');
  }
</script>

<button 
    class="data-theme-btn dark-hidden"
    onclick="toggleTheme('dark');">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="#3f4b67" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/></svg>
</button>
<button 
    class="data-theme-btn light-hidden"
    onclick="toggleTheme('light');">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="#e9e9e9" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><path d="M12 1v2m0 18v2M4.2 4.2l1.4 1.4m12.8 12.8l1.4 1.4M1 12h2m18 0h2M4.2 19.8l1.4-1.4M18.4 5.6l1.4-1.4"/></svg>
</button>
</div></div></section><section id="content"><div class="article-containter">
<section class="article-header">
    <h1>Proximal Policy Gradient</h1><p class="article-date">2021-07-02</p></section><section class="article-labels">
    <a class="article-tag li" href=/tags/ai/><span class="hashtag">#</span>AI</a><a class="article-tag li" href=/tags/ppo/><span class="hashtag">#</span>PPO</a><a class="article-tag li" href=/tags/drl/><span class="hashtag">#</span>DRL</a></section><article class="markdown-body"><hr>
<h3 id="policy-gradient">Policy Gradient</h3>
<ul>
<li>Consider a stochastic, parameterized policy, $$\pi_{\theta}$$.</li>
<li>Aim: maximize the expected return $$J(\pi_{\theta}) = E_{\tau \sim \pi_{\theta}}{\Bigl[R(\tau)\Bigr]}$$.</li>
<li>Optimize the policy by gradient ascent,
$$\theta_{k+1} = \theta_k + \alpha \left. \nabla_{\theta} J(\pi_{\theta}) \right|_{\theta_k}$$.</li>
<li>$$\nabla_{\theta} J(\pi_{\theta})$$ = gradient of policy performance = policy gradient</li>
<li>To use this algorithm, need an numerical expression in two steps:
<ol>
<li>deriving the analytical gradient of policy performance, which turns out to have the form of an expected value, and then</li>
<li>forming a sample estimate of that expected value, which can be computed with data from a finite number of agent-environment interaction steps.</li>
</ol>
</li>
</ul>
<blockquote>
<h4 id="policy-gradient-expression-for-grad-log-prob">Policy Gradient Expression for grad-log-prob:</h4>
<p>$$\nabla_{\theta} J(\pi_{\theta}) = \nabla_{\theta} E_{\tau \sim \pi_{\theta}}{\Bigl[R(\tau)\Bigr]}  = &hellip;=  E_{\tau \sim \pi_{\theta}}{\Bigl[\sum_{t=0}^{T} \nabla_{\theta} \log \pi_{\theta}(a_t |s_t) R(\tau)\Bigr]}$$</p>
</blockquote>
<p>$$&hellip;=\nabla_{\theta} \int_{\tau} P(\tau|\theta) R(\tau)  $$<br>
$$&hellip;= \int_{\tau} \nabla_{\theta} P(\tau|\theta) R(\tau)  $$<br>
$$&hellip;= \int_{\tau} P(\tau|\theta) \nabla_{\theta} \log P(\tau|\theta) R(\tau) $$<br>
$$&hellip;= E_{\tau \sim \pi_{\theta}}{\Bigl[\nabla_{\theta} \log P(\tau|\theta) R(\tau)\Bigr]} $$</p>
<blockquote>
<h4 id="policy-gradient-is-an-expectation-thus-estimate-it-with-a-sample-mean">Policy Gradient is an <strong>expectation</strong>, thus estimate it with a sample mean:</h4>
<ul>
<li>If we collect a set of trajectories $$ \mathcal{D} = \{\tau_i\}_{i=1,&hellip;,N}$$</li>
</ul>
<p>where each trajectory is obtained by letting the agent act in the environment
using the policy $$\pi_{\theta}$$,</p>
<ul>
<li>The policy gradient can be estimated with
$$\hat{g} = \frac{1}{|\mathcal{D}|} \sum_{\tau \in \mathcal{D}} \sum_{t=0}^{T} \nabla_{\theta} \log \pi_{\theta}(a_t |s_t) R(\tau)$$,</li>
</ul>
<p>where $$|\mathcal{D}|$$ is the number of trajectories in $$\mathcal{D}$$ (here, N).</p>
</blockquote>
<ul>
<li>Assuming that we have represented our policy in a way which allows us to calculate
$$\nabla_{\theta} \log \pi_{\theta}(a|s)$$,
and if we are able to run the policy in the environment to collect the trajectory dataset, we can compute the policy gradient and take an update step.</li>
</ul>
<hr>
<h3 id="implementing-the-policy-gradient">Implementing the Policy Gradient</h3>
<ol>
<li>Making the Policy Network.</li>
</ol>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback"># make core of policy network
logits_net = mlp(sizes=[obs_dim]+hidden_sizes+[n_acts])

# make function to compute action distribution
def get_policy(obs):
    logits = logits_net(obs)
    return Categorical(logits=logits)

# make action selection function (outputs int actions, sampled from policy)
def get_action(obs):
    return get_policy(obs).sample().item()
</code></pre></div><ol start="2">
<li>Making the Loss Function.<br>
When the right data (a set of state, action, weight tuples) collected from<br>
while acting according to the policy, the gradient of this loss is equal to the policy gradient.</li>
</ol>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback"># make loss function whose gradient, for the right data, is policy gradient
def compute_loss(obs, act, weights):
    logp = get_policy(obs).log_prob(act)
    return -(logp * weights).mean()
</code></pre></div><blockquote>
<p>Note that the <strong>loss function</strong> here is different from supervised learning as following:</p>
<ol>
<li>In Policy Gradient, the data distribution depends on the parameters we aim to optimize, i.e. the data
must be sampled on the most recent policy.
(cf. In supervised learning, a loss function is usually defined on a fixed data distribution)</li>
<li>In Policy Gradient, the loss function doesn&rsquo;t measure performance, is only useful when evaluated
at the current parameters.  Note that what we care about is expected return,  $$J(\pi_{\theta})$$.
(cf. In supervised learning, a loss function usually evaluates the performance metric that we care about)</li>
</ol>
</blockquote>
</article>
</div><section class="article-navigation"><p><a class="link" href="/ai/deep-reinforcement-learning/"><span class="li"></span>Deep Reinforcement Learning</a></p><p><a class="link" href="/ai/posterior-probability/"><span class="li"></span>Posterior Probability</a class="link">
    </p></section></section><section id="footer" class="footer max-body-width"><div class="footer-wrap"><p class="copyright">iPark memoization</p></div>
<div class="footer-wrap"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a><span> | </span><a href="/index.xml" target="_blank" rel="noopener"> RSS</a></div>
<div class="footer-wrap"><p class="powerby"><span>Powered by </span><a href="https://gohugo.io" 
    target="_blank" rel="noopener">Hugo</a><span> and the </span><a href="https://github.com/qdzhang/hugo-notepadium-mod" 
    target="_blank" rel="noopener">Notepadium-mod</a></p></div>
<div class="footer-wrap">
    <a onclick='window.scrollTo({top: 0, behavior: "smooth"});'>^ TOP ^</a>
</div></section><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/&#43;DiW/UqRcLbRjq" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l&#43;B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd&#43;qj&#43;o24G5ZU2zJz" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script></div>
</body>

</html>